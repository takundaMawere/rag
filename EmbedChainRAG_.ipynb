{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vV2SbexoWta"
      },
      "outputs": [],
      "source": [
        "!pip install embedchain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XuF3RXf5_9Ny"
      },
      "outputs": [],
      "source": [
        "!pip install docx2txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikCqdFDtpK5h"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGUKvnnR8qV7"
      },
      "outputs": [],
      "source": [
        "!pip install dropbox\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pT91R8Wz8Vpa"
      },
      "outputs": [],
      "source": [
        "!pip install pdf2image pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNxywke7_wEC"
      },
      "outputs": [],
      "source": [
        "!apt-get install poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtN_KVbe_xe7"
      },
      "outputs": [],
      "source": [
        "!apt-get install tesseract-ocr\n",
        "!apt-get install liptesseract-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MXZvySO7X9r"
      },
      "outputs": [],
      "source": [
        "import dropbox\n",
        "import os\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "\n",
        "from embedchain import App\n",
        "# Replace this with your HF token\n",
        "os.environ[\"HUGGINGFACE_ACCESS_TOKEN\"] = \"hfxxx\"\n",
        "os.environ[\"DROPBOX_ACCESS_TOKEN\"] = \"slxxx\"\n",
        "config = {\n",
        "  'llm': {\n",
        "    'provider': 'huggingface',\n",
        "    'config': {\n",
        "      'model': 'mistralai/Mistral-7B-Instruct-v0.2',\n",
        "      'top_p': 0.5\n",
        "    }\n",
        "  },\n",
        "  'embedder': {\n",
        "    'provider': 'huggingface',\n",
        "    'config': {\n",
        "      'model': 'sentence-transformers/all-mpnet-base-v2'\n",
        "    }\n",
        "  }\n",
        "}\n",
        "# Dropbox API access token\n",
        "ACCESS_TOKEN = 'slxxx'\n",
        "\n",
        "# Create a Dropbox client\n",
        "dbx = dropbox.Dropbox(ACCESS_TOKEN)\n",
        "\n",
        "# Dropbox folder path\n",
        "dropbox_folder_path = '/test'\n",
        "\n",
        "# Local folder to save downloaded PDFs\n",
        "local_folder_path = './downloaded_pdfs'\n",
        "os.makedirs(local_folder_path, exist_ok=True)\n",
        "\n",
        "# List and download PDFs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVV4uLq68_jy",
        "outputId": "e43739b9-801f-4ef4-bb1a-1717e015666d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded PDFs: ['Tecno 2021.pdf', '2023ICS2205examsol.pdf', 'TEC301 - Course Outline (1).pdf']\n"
          ]
        }
      ],
      "source": [
        "def list_and_download_pdfs(dbx, folder_path):\n",
        "    pdf_files = []\n",
        "    result = dbx.files_list_folder(folder_path)\n",
        "    while result.entries:\n",
        "        for entry in result.entries:\n",
        "            if isinstance(entry, dropbox.files.FileMetadata) and entry.name.endswith('.pdf'):\n",
        "\n",
        "                local_file_path = os.path.join(local_folder_path, entry.name)\n",
        "                if not os.path.exists(local_file_path):\n",
        "                    pdf_files.append(entry.name)\n",
        "                with open(local_file_path, \"wb\") as f:\n",
        "                    metadata, res = dbx.files_download(entry.path_lower)\n",
        "                    f.write(res.content)\n",
        "        if result.has_more:\n",
        "            result = dbx.files_list_folder_continue(result.cursor)\n",
        "        else:\n",
        "            break\n",
        "    return pdf_files\n",
        "\n",
        "pdf_files = list_and_download_pdfs(dbx, dropbox_folder_path)\n",
        "print(f\"Downloaded PDFs: {pdf_files}\")\n",
        "\n",
        "# Convert PDFs to text using OCR\n",
        "def pdf_to_text(pdf_path):\n",
        "    pages = convert_from_path(pdf_path, 300)\n",
        "    texts = [pytesseract.image_to_string(page) for page in pages]\n",
        "    return \"\\n\".join(texts)\n",
        "\n",
        "pdf_texts = []\n",
        "for pdf_file in pdf_files:\n",
        "    local_pdf_path = os.path.join(local_folder_path, pdf_file)\n",
        "    text = pdf_to_text(local_pdf_path)\n",
        "    pdf_texts.append((pdf_file, text))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwSw144BN3lj"
      },
      "outputs": [],
      "source": [
        "app = App.from_config(config=config)\n",
        "# Add extracted texts to EmbedChain\n",
        "for pdf_file, text in pdf_texts:\n",
        "    app.add(text, data_type='text')\n",
        "app.add(\"/general\", data_type=\"dropbox\")\n",
        "# Query the embedded texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogNOScMFYIy-"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit\n",
        "!pip install py-localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C65v1NjVYR1g",
        "outputId": "e4b9ffaa-9708-430a-e1d0-77858962e72b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test.py\n",
        "from embedchain import App\n",
        "import os\n",
        "os.environ[\"HUGGINGFACE_ACCESS_TOKEN\"] = \"hfxxx\"\n",
        "config = {\n",
        "  'llm': {\n",
        "    'provider': 'huggingface',\n",
        "    'config': {\n",
        "      'model': 'mistralai/Mistral-7B-Instruct-v0.2',\n",
        "      'top_p': 0.5\n",
        "    }\n",
        "  },\n",
        "  'embedder': {\n",
        "    'provider': 'huggingface',\n",
        "    'config': {\n",
        "      'model': 'sentence-transformers/all-mpnet-base-v2'\n",
        "    }\n",
        "  }\n",
        "}\n",
        "app = App.from_config(config=config)\n",
        "import streamlit as st\n",
        "prompt = st.chat_input(\"What's on your mind\")\n",
        "with st.chat_message(\"user\"):\n",
        "    st.write(prompt)\n",
        "response = app.query(prompt)\n",
        "with st.chat_message(\"assistant\"):\n",
        "    st.markdown(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37p2CoKDkrDx",
        "outputId": "a0773a11-90e1-4d84-c7f3-52582cc0c0f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting rag.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile rag.py\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "from embedchain import App\n",
        "import streamlit as st\n",
        "config = {\n",
        "  'llm': {\n",
        "    'provider': 'huggingface',\n",
        "    'config': {\n",
        "      'model': 'mistralai/Mistral-7B-Instruct-v0.2',\n",
        "      'top_p': 0.5\n",
        "    }\n",
        "  },\n",
        "  'embedder': {\n",
        "    'provider': 'huggingface',\n",
        "    'config': {\n",
        "      'model': 'sentence-transformers/all-mpnet-base-v2'\n",
        "    }\n",
        "  }\n",
        "}\n",
        "with st.sidebar:\n",
        "    st.title(\"HIT AI\")\n",
        "    st.caption(\"ðŸš€ Powered by Afrinity Technologies!\")\n",
        "    if st.button(\"âž•Start New Chat\"):\n",
        "      st.session_state.messages = [\n",
        "          {\n",
        "              \"role\": \"assistant\",\n",
        "              \"content\": \"Hi! I'm HIT AI Assistant. Ask me anything :)\"\n",
        "          }\n",
        "      ]\n",
        "      st.experimental_rerun()\n",
        "\n",
        "#     huggingface_access_token = st.text_input(\"Hugging face Token\", key=\"chatbot_api_key\", type=\"password\")\n",
        "#     \"[Get Hugging Face Access Token](https://huggingface.co/settings/tokens)\"\n",
        "#     \"[View the source code](https://github.com/embedchain/examples/mistral-streamlit)\"\n",
        "def extract_answer(response):\n",
        "    # Split the response by lines\n",
        "    lines = response.split('\\n')\n",
        "\n",
        "    # Find the line that starts with \"Answer:\" to get the answer section\n",
        "    answer_index = next(i for i, line in enumerate(lines) if line.startswith(\"Answer:\"))\n",
        "\n",
        "    # Return the part of the response starting from the answer index + 1 (to skip \"Answer:\")\n",
        "    answer = '\\n'.join(lines[answer_index + 1:])\n",
        "\n",
        "    return answer.strip()\n",
        "\n",
        "def response_generator(resp):\n",
        "    for word in resp.split():\n",
        "        yield word + \" \"\n",
        "        time.sleep(0.05)\n",
        "# # Sample usage\n",
        "# response = app.query(\"Where is Chapati located\")\n",
        "# answer = extract_answer(response)\n",
        "# print(answer)\n",
        "\n",
        "st.title(\"HIT AI\")\n",
        "st.caption(\"ðŸš€ Powered by Afrinity Technologies!\")\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = [\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"\"\"\n",
        "        Hi! I'm HIT AI Assistant. Ask me anything :)\n",
        "        \"\"\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "if prompt := st.chat_input(\"Ask me anything!\"):\n",
        "    msg_placeholder = st.empty()\n",
        "    # if not st.session_state.chatbot_api_key:\n",
        "    #     st.error(\"Please enter your Hugging Face Access Token\")\n",
        "    #     st.stop()\n",
        "\n",
        "    # os.environ[\"HUGGINGFACE_ACCESS_TOKEN\"] = st.session_state.chatbot_api_key\n",
        "    os.environ[\"HUGGINGFACE_ACCESS_TOKEN\"] = \"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\"\n",
        "    app = App.from_config(config=config)\n",
        "\n",
        "    if prompt.startswith(\"/add\"):\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.markdown(prompt)\n",
        "            st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "        prompt = prompt.replace(\"/add\", \"\").strip()\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            message_placeholder = st.empty()\n",
        "            message_placeholder.markdown(\"Adding to knowledge base...\")\n",
        "            app.add(prompt)\n",
        "            message_placeholder.markdown(f\"Added {prompt} to knowledge base!\")\n",
        "            st.session_state.messages.append({\"role\": \"assistant\", \"content\": f\"Added {prompt} to knowledge base!\"})\n",
        "            st.stop()\n",
        "\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(prompt)\n",
        "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        msg_placeholder = st.empty()\n",
        "        msg_placeholder.markdown(\"Thinking...\")\n",
        "        full_response = \"\"\n",
        "\n",
        "        for response in extract_answer(app.query(prompt)):\n",
        "            msg_placeholder.empty()\n",
        "            full_response += response\n",
        "\n",
        "        st.write_stream(response_generator(full_response))\n",
        "        # msg_placeholder.markdown(full_response)\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdC4vgPx4WRe",
        "outputId": "f6eb77a4-d446-4b70-e577-8e884e16748c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25hremoved 22 packages in 0.33s\n",
            "\u001b[K\u001b[?25h/tools/node/bin/lt -> /tools/node/lib/node_modules/localtunnel/bin/lt.js\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors in 1.663s\n"
          ]
        }
      ],
      "source": [
        "!npm uninstall -g localtunnel\n",
        "!npm install -g localtunnel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j0qU_L4YSty",
        "outputId": "22d6d0ec-f2ce-43fb-a01b-73ab45217df6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.094s\n",
            "your url is: https://long-ducks-vanish.loca.lt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import time\n",
        "streamlit_proc = subprocess.Popen(['streamlit', 'run', 'rag.py'])\n",
        "time.sleep(5)\n",
        "# !curl https://loca.lt/mytunnelpassword\n",
        "\n",
        "!npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjT0_TqeYajP",
        "outputId": "e40895f8-d236-470c-fec1-3969ae1be00f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.125.226.15"
          ]
        }
      ],
      "source": [
        "!curl https://loca.lt/mytunnelpassword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmiP-5yS9BtC"
      },
      "outputs": [],
      "source": [
        "\n",
        "query = \"What are the course objectives for TEC 301\"\n",
        "response = app.query(query)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzVNlMjgPHXG"
      },
      "outputs": [],
      "source": [
        "[theme]\n",
        "\n",
        "primaryColor=\"#d33682\"\n",
        "backgroundColor=\"#002b36\"\n",
        "secondaryBackgroundColor=\"#586e75\"\n",
        "textColor=\"#fafafa\"\n",
        "font=\"sans serif\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
